---
title: "Covid Flight Analysis"
author: "Group 2"
date: "4/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#put all libraries used in the report here 
library(tidyverse)
library(patchwork)
```


```{r data processing, include = FALSE, cache = TRUE}
#This will not be visible in the rendered version of the report

flights <- read.csv("./jantojun2020.csv")
us_states <- read.csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")

desired_cols <- c(2,3,4,5,6,7,10,13,14,17,18,20,25,28,29,31,36,40,41) # desired columns
names(flights[,desired_cols]) # columns kept
flights2 <- flights[,desired_cols] # dataframe with correct columns

clean_flights0 <- flights2 %>% # correcting column data types
  mutate(DISTANCE = as.double(DISTANCE)) %>% 
  mutate(CANCELLED = as.logical(CANCELLED)) %>%
  mutate(FL_DATE = as.Date(FL_DATE,format = "%m/%d/%y"))

us_states2 <- us_states [,-3] %>% # removing "fips" column and dates after flights dataset
  mutate(date = as.Date(date)) %>%
  subset(date <= max(clean_flights0$FL_DATE)) # dropping data after the latest flight date
length(which(rowSums(is.na(us_states2)) > 0)) # checking number of rows with NA values in data set

# CANCELLED column leaves NA in other columns
clean_flights0_length <- nrow(clean_flights0) # number of rows in dataset
# number of not cancelled flights with missing data
num_na_rows <- length(which(rowSums(is.na(clean_flights0)) > 0 & 
                              clean_flights0$CANCELLED == 0)) 
# share of rows with NA values
share_na <- num_na_rows / clean_flights0_length
# number of fully filled rows
num_filled_rows <- clean_flights0_length - num_na_rows 
# share of rows with missing information
share_na
# number of rows with full information
num_filled_rows
# rows  with missing information
bad_rows <- which(rowSums(is.na(clean_flights0)) > 0 & 
                    clean_flights0$CANCELLED == 0)
# eliminating incomplete rows
clean_flights1 <- clean_flights0[-bad_rows,]

c_clean <- clean_flights1 %>% # non-numeric dates
            select_if(is.double)
# only continuous columns w/ NA values
c_clean0 <- clean_flights0 %>% 
            select_if(is.double) %>%
            mutate(FL_DATE = as.numeric(clean_flights0$FL_DATE)) 
# only continuous columns w/o NA values
c_clean1 <- clean_flights1 %>% 
            select_if(is.double) %>%
            mutate(FL_DATE = as.numeric(clean_flights1$FL_DATE)) 
# only discrete columns w/o NA values
d_clean1 <- clean_flights1 %>% select_if(Negate(is.double))
# only continuous columns w/ NA values (randomly sampled)
sampled_rows <- sample(1:nrow(d_clean1), nrow(d_clean1), replace = FALSE)
d_clean0 <- clean_flights0[sampled_rows,]

new_flights <- cbind(d_clean1, c_clean)

# left join by date and ORIGIN STATE
fulldata <- left_join(new_flights, us_states2, by = c(c("FL_DATE" = "date"), c("ORIGIN_STATE_NM" = "state")))
# removing rows that have cases or deaths as "NA"
num_na_rows <- length(which(is.na(fulldata$cases) == TRUE | is.na(fulldata$deaths) == TRUE)) 
bad_rows <- which(is.na(fulldata$cases) == TRUE | is.na(fulldata$deaths) == TRUE)
fulldata2 <- fulldata[-bad_rows,]
# converting NA values to 0
fulldata3 <- fulldata
fulldata3[is.na(fulldata)] <- 0
fulldata3 <- fulldata3 %>%
  mutate(cases = as.integer(cases)) %>% # making discrete column integer
  mutate(deaths = as.integer(deaths)) # making discrete column integer
head(fulldata3) # NA values are converted to 0
```

## Introduction and Overview of Data
```{r}

```

## Analysis of Key Variables
```{r random sample, include = FALSE}
slim_data = fulldata3 %>% 
  select(ARR_DELAY, DISTANCE, ORIGIN, ORIGIN_STATE_NM, deaths)

names(slim_data) = tolower(names(slim_data))

#speed up initial plot development by randomly sampling 10% of the population
sample_row_index = sample(1:nrow(slim_data), nrow(slim_data)/10)

fulldata3_copy = fulldata3 #so i can change the col names to lowercase to work with code I have written without messing up others code
names(fulldata3_copy) = tolower(names(fulldata3_copy))

#slim_sample is now the full data
slim_sample = fulldata3_copy #slim_data[sample_row_index,]  
```

### Arrival Delay and Distance
One might think that longer flights are expected to have longer delays. This turns out not to be true. Arrival delays and flight distance are very weakly correlated, with a spearman correlation coefficient (able to detect non-linear trends) of only -0.022. A scatterplot between these two variables suggests that these variables are relatively unrelated as well. 

```{r arrival delay and distance, echo = FALSE, cache = TRUE}
no_delay = sum(slim_sample$arr_delay <= 0) / length(slim_sample$arr_delay) 
correlation = cor(slim_sample$arr_delay, slim_sample$distance, method = "spearman")

ggplot(slim_sample, aes(distance, arr_delay)) +
  geom_point() +
  labs(x = "Distance (Miles)",
       y = "Arrival Delay (Minutes)",
       title = "Distance vs Arrival Delay")
```


Alternatively, we can examine boxplots of flight distance grouped by every 1000 miles, and see that the distribution of arrival delays is nearly identical in all cases. Outliers have been removed because they obscure most of the distributions since there are some very high outliers. Note that the third quartile is near zero for every boxplot, meaning that 75% of the flights actually arrive on time or early. 

```{r arrival delay and distance 2, echo = FALSE, cache = TRUE}
#calculate quantiles to filter out outliers 
iqr =  quantile(slim_sample$arr_delay, 0.75) - quantile(slim_sample$arr_delay, 0.25)
upper_outlier_q = quantile(slim_sample$arr_delay, 0.75) + 1.5 * iqr
lower_outlier_q = quantile(slim_sample$arr_delay, 0.25) - 1.5 * iqr

slim_sample %>% 
  filter(arr_delay <= upper_outlier_q) %>% 
  filter(arr_delay >= lower_outlier_q) %>% 
ggplot(aes(distance, arr_delay)) +
  geom_boxplot(aes(group = cut_width(distance, 1000))) +
  labs(x = "Distance", 
       y = "Arrival Delay",
       title = "Arrival Delay Grouped in 1000 Mile Bins w/o Outliers")
```


### Arrival Delay and Covid Deaths
Arrival delays were compared with covid deaths on that particular day, serving as a proxy for the severity of covid. Even though these data are from near the peak of covid, only 42% of the dates in this range have any covid deaths at all. The Spearman correlation coefficient for arrival delays and deaths is -0.05. A graphical approach with the scatterplot also suggests a weak association.

```{r arrival delay and deaths, echo = FALSE, cache = TRUE}
death_correlation = cor(slim_sample$arr_delay, slim_sample$deaths, method = "spearman")

zero_death_days = sum(slim_sample$deaths == 0) / length(slim_sample$deaths)

ggplot(slim_sample, aes(deaths, arr_delay)) + 
  geom_point() +
  labs(x = "Covid Related Deaths",
       y = "Arrival Delay",
       title = "Covid Deaths vs Arrival Delay")

lm = lm(arr_delay ~ deaths, data = slim_sample)
```

### Arrival Delay and Origin
One variable that seems to significantly influence arrival delays is the airport the flight originated from. A one way ANOVA test of delay modeled by origin reveals that there are statistically significant differences in arrival delays among airports. The rejection of the null hypothesis is unsurprising as there are 375 airports in the data set. The best and the worst airports to fly from are shown below.
```{r arrival delay and origin, echo = FALSE, cache = TRUE}
longest_origin_delays = slim_sample %>% 
  group_by(origin) %>% 
  summarize(mean_delay = mean(arr_delay)) %>% 
  arrange(desc(mean_delay)) %>% 
  head(10)

shortest_origin_delays = slim_sample %>% 
  group_by(origin) %>% 
  summarize(mean_delay = mean(arr_delay)) %>% 
  arrange(desc(mean_delay)) %>% 
  tail(10)

p1 = ggplot(longest_origin_delays) + 
  geom_col(aes(rev(reorder(origin, mean_delay)), mean_delay)) +
  labs(x = "Origin", 
       y = "Mean Delay in Minutes",
       title = "10 Worst Airports to Fly From")

p2 = ggplot(shortest_origin_delays) + 
geom_col(aes(reorder(origin, mean_delay), abs(mean_delay))) +
labs(x = "Origin", 
     y = "Mean Minutes Arrived Early",
     title = "10 Best Airports to Fly From")
 
p1 + p2
```
